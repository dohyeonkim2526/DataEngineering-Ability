import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from matplotlib import rc
from sklearn.tree import export_graphviz
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_roc_curve, roc_curve, auc 
from sklearn.metrics import roc_auc_score
from sklearn.multiclass import OneVsRestClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
import graphviz
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

row_data='/Users/gimdohyeon/Documents/캡스톤디자인/데이터/fire_dataset.csv'
data=pd.read_csv(row_data, encoding='euc-kr')

data=data.dropna()
data=data.reset_index(drop=True)

#%%
# x=data.drop('재산피해소계', axis=1)
data=data.drop(['발화열원','발화열원소분류','발화요인소분류','최초착화물소분류','발화관련기기소분류','건물상태','장소대분류','장소소분류','발화지점대분류','층수(지상)','층수(지하)','화재유형',
            '발화지점소분류'],axis=1)

x=data
x.columns

x['건물층수']=x['건물층수(지상)']+x['건물층수(지하)']
x=x.drop(['건물층수(지상)','건물층수(지하)','발화층'], axis=1)



#%%
x=x.drop(['발화요인대분류','최초착화물대분류','발화관련기기대분류','장소중분류',
          '펌프물탱크','다중이용업여부','방화관리대상여부','건물구조조','날씨','온도(℃)'], axis=1)
x=x.dropna()
x.reset_index(drop=True)

ind_x=x[x['풍속']=='NONE'].index
x=x.drop(ind_x)
x=x.reset_index(drop=True)


#%%
rc('font',family='AppleGothic',size=8)
plt.rcParams['axes.unicode_minus']=False

#sns.pairplot(x)


#%%
cols=x.columns
objcols=[]

for i in range(len(cols)):
    if x[cols[i]].dtypes=='object':
        objcols.append(cols[i])
        
def Label(df):
    features=objcols
    for feature in features:
        le=LabelEncoder()
        df[feature]=le.fit_transform(df[feature])
    return df


# 각 레이블 인코더 변환 확인하는 함수 
le_df=[]
for i in range(len(objcols)):
    le=LabelEncoder()
    col=x[objcols[i]].unique()
    col_le=le.fit_transform(col)
    col_inv=le.inverse_transform(col_le)
    df=pd.DataFrame(col_le, col_inv)
    le_df.append(df)

        
#%%
y=x.재산피해소계
bins=[0,120,700,5000]
y=np.digitize(y, bins)
y=pd.Series(y, name='재산피해소계')

x['재산피해소계']=y

Y=x.재산피해소계
x=x.drop('재산피해소계', axis=1)
x_original=x.copy()

# 원본 데이터에서 문자열 속성만 LabelEncoder()
X=Label(x)


#%%
plot=Y.value_counts().sort_index(ascending=True).plot.bar(color='royalblue')
plot.set_xticklabels(['0-120','120-700','700-5000','more than 5000'], rotation=0)

# 재산피해액(y)의 값에 따라 4개의 레이블로 나눈다.
import collections
dict={}
dict=collections.Counter(Y)
dict # 각 레이블 갯수 비교


#%%

# 모델 학습
X_train, X_test, y_train, y_test=train_test_split(X, Y, test_size=.25, random_state=42)

#tree=DecisionTreeClassifier(max_depth=10,
#                            min_samples_leaf=30,
#                            min_samples_split=30,
#                            max_leaf_nodes=30,
#                            splitter='best',
#                            criterion='gini')


# tree=DecisionTreeClassifier(max_depth=20,
#                             min_samples_leaf=10,
#                             min_samples_split=10,
#                             splitter='best',
#                             criterion='gini')

tree=DecisionTreeClassifier(max_depth=50,
                            min_samples_leaf=3,
                            min_samples_split=10,
                            splitter='best',
                            criterion='gini')

tree.fit(X_train, y_train)
print('Training accuracy: ',tree.score(X_train, y_train))

y_pred=tree.predict(X_test)

scores={}
scores['DT']=accuracy_score(y_test, y_pred)

train_acc={}
train_acc['DT']=tree.score(X_train, y_train)


#%%
# Decision Tree 확인
# export_graphviz(tree,
#                 out_file="tree.dot",
#                 feature_names=X.columns,
#                 #class_names=['관심','주의','경고','위험'],
#                 class_names=['0-120','120-700','700-5000','more than 5000'],
#                 rounded=True, #둥근 노드 상자와 Helvetica 폰트 사용
#                 filled=True #노드의 클래스가 구분되도록 색을 채워줌
#                 )

# with open("tree.dot") as f:
#     dot_graph=f.read()   
   
# dot=graphviz.Source(dot_graph)
# dot.format='png'
# dot.render(filename="tree_0508", directory="/Users/gimdohyeon/Desktop/캡스톤디자인(2)/tree_model", cleanup=True) #트리 저장할때마다 파일명 바꿔주기


#%%
print(tree.feature_importances_)

def plot_feature_importance(model):
    n_features=X.shape[1]
    plt.figure(dpi=150) #고해상도 plot(기본100)
    plt.barh(range(n_features), model.feature_importances_, align='center')
    plt.yticks(np.arange(n_features), X.columns)
    plt.xlabel('feature importance')
    plt.ylabel('feature')
    plt.ylim(-1, n_features)

plot_feature_importance(tree)


#%%
RF_model=RandomForestClassifier(n_estimators=5, random_state=1)
RF_model.fit(X_train,y_train)
y_pred=RF_model.predict(X_test)

scores['RF']=accuracy_score(y_test, y_pred)
train_acc['RF']=RF_model.score(X_train, y_train)

print('RandomForest Training accuracy: ', RF_model.score(X_train, y_train))


#%%
SVC_model=SVC(C=10, gamma=0.1)
SVC_model.fit(X_train, y_train)
y_pred=SVC_model.predict(X_test)

scores['SVC']=accuracy_score(y_test, y_pred)
train_acc['SVC']=SVC_model.score(X_train, y_train)

print('SVM Training accuracy', SVC_model.score(X_train, y_train))
